{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading minimal training data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from lightgbm import LGBMRegressor\n",
    "import gc\n",
    "import json\n",
    "from pathlib import Path\n",
    "from numerapi import NumerAPI\n",
    "import pickle\n",
    "\n",
    "\"\"\"Era Split Model\"\"\"\n",
    "from sklearn.ensemble import EraHistGradientBoostingRegressor\n",
    "\n",
    "'''Baseline Model'''\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "napi = NumerAPI()\n",
    "\n",
    "Path(\"./v4\").mkdir(parents=False, exist_ok=True)\n",
    "# napi.download_dataset(\"v4/train.parquet\")\n",
    "# napi.download_dataset(\"v4/validation.parquet\")\n",
    "# napi.download_dataset(\"v4/live.parquet\", f\"v4/live_{current_round}.parquet\")\n",
    "# napi.download_dataset(\"v4/validation_example_preds.parquet\")\n",
    "# napi.download_dataset(\"v4/features.json\")\n",
    "\n",
    "print('Reading minimal training data')\n",
    "# read the feature metadata and get a feature set (or all the features)\n",
    "with open(\"v4/features.json\", \"r\") as f:\n",
    "    feature_metadata = json.load(f)\n",
    "features = feature_metadata[\"feature_sets\"]['small']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_save( model, trial_identifier, fit_eras = False ):\n",
    "    if fit_eras:\n",
    "        model.fit(training_data[ features ], training_data[ TARGET_COL ], training_data['era'].values)\n",
    "    else:\n",
    "        model.fit(training_data[ features ], training_data[ TARGET_COL ])\n",
    "    validation_data.loc[:, f\"preds_{trial_identifier}\"] = model.predict( validation_data[features] )\n",
    "\n",
    "    corrs = validation_data.groupby('era').apply( \n",
    "        lambda x: x[[f\"preds_{trial_identifier}\", TARGET_COL]].corr().iloc[0,1] \n",
    "    )\n",
    "\n",
    "    desc = corrs.describe()\n",
    "    desc['sharpe'] = corrs.mean()/corrs.std()\n",
    "    desc['win_rate'] = ( corrs.dropna() > 0 ).sum() / len(corrs)\n",
    "\n",
    "    # Save the trained model with trial identifier\n",
    "    model_filename = f\"{trial_identifier}_model.pkl\"\n",
    "    with open(model_filename, \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "\n",
    "    # Save the desc DataFrame with trial identifier\n",
    "    desc_filename = f\"{trial_identifier}_desc.csv\"\n",
    "    desc.to_csv(desc_filename, index=True)\n",
    "\n",
    "    # Save the validation data with predictions and trial identifier\n",
    "    validation_data_filename = f\"{trial_identifier}_validation_data_with_preds.csv\"\n",
    "    validation_data[[f'preds_{trial_identifier}']].to_csv(validation_data_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL=\"target_cyrus_v4_20\"\n",
    "\n",
    "training_data = pd.read_parquet('v4/train.parquet')\n",
    "validation_data = pd.read_parquet('v4/validation.parquet')\n",
    "\n",
    "# features = [ f for f in list(training_data) if 'feature' in f ]\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "# Define a trial identifier string\n",
    "trial_identifier = \"baseline\"  # You can change this to identify different trials\n",
    "\n",
    "model = HistGradientBoostingRegressor( \n",
    "    early_stopping=False, \n",
    "    max_iter=n_iter, \n",
    "    max_depth=5, \n",
    "    learning_rate=.1, \n",
    "    colsample_bytree=.1, \n",
    "    max_leaf_nodes=32, \n",
    "\n",
    ")\n",
    "\n",
    "run_save( model, trial_identifier )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Era Split'''\n",
    "\n",
    "training_data['era'] = training_data['era'].astype('int')\n",
    "\n",
    "trial_identifier = \"erasplit\"\n",
    "\n",
    "model = EraHistGradientBoostingRegressor( \n",
    "    early_stopping=False, \n",
    "    boltzmann_alpha=0, \n",
    "    max_iter=n_iter, \n",
    "    max_depth=5, \n",
    "    learning_rate=.1, \n",
    "    colsample_bytree=.1, \n",
    "    max_leaf_nodes=32, \n",
    "    gamma=0, \n",
    "    blama=0, \n",
    "    era_boosting=False,\n",
    "    gain_debug=False,\n",
    "    vanna=0\n",
    ")\n",
    "run_save( model, trial_identifier, fit_eras=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Era Split Mixin'''\n",
    "\n",
    "trial_identifier = \"erasplit_mixin\"\n",
    "\n",
    "training_data['era'] = training_data['era'].astype('int')\n",
    "\n",
    "era_model = EraHistGradientBoostingRegressor( \n",
    "    early_stopping=False, \n",
    "    boltzmann_alpha=0, \n",
    "    max_iter=n_iter, \n",
    "    max_depth=5, \n",
    "    learning_rate=.1, \n",
    "    colsample_bytree=.1, \n",
    "    max_leaf_nodes=32, \n",
    "    gamma=0.5, \n",
    "    blama=0, \n",
    "    era_boosting=False,\n",
    "    gain_debug=False,\n",
    "    vanna=0\n",
    ")\n",
    "run_save( model, trial_identifier, fit_eras=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Directional Era Split'''\n",
    "\n",
    "trial_identifier = \"directional_erasplit\"\n",
    "\n",
    "training_data['era'] = training_data['era'].astype('int')\n",
    "\n",
    "era_model = EraHistGradientBoostingRegressor( \n",
    "    early_stopping=False, \n",
    "    boltzmann_alpha=0, \n",
    "    max_iter=n_iter, \n",
    "    max_depth=5, \n",
    "    learning_rate=.1, \n",
    "    colsample_bytree=.1, \n",
    "    max_leaf_nodes=32, \n",
    "    gamma=0, \n",
    "    blama=1, \n",
    "    era_boosting=False,\n",
    "    gain_debug=False,\n",
    "    vanna=0\n",
    ")\n",
    "run_save( model, trial_identifier, fit_eras=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Directional Era Split Mixin'''\n",
    "\n",
    "trial_identifier = \"directional_erasplit_mixin\"\n",
    "\n",
    "training_data['era'] = training_data['era'].astype('int')\n",
    "\n",
    "era_model = EraHistGradientBoostingRegressor( \n",
    "    early_stopping=False, \n",
    "    boltzmann_alpha=0, \n",
    "    max_iter=n_iter, \n",
    "    max_depth=5, \n",
    "    learning_rate=.1, \n",
    "    colsample_bytree=.1, \n",
    "    max_leaf_nodes=32, \n",
    "    gamma=0.5, \n",
    "    blama=0.5, \n",
    "    era_boosting=False,\n",
    "    gain_debug=False,\n",
    "    vanna=0\n",
    ")\n",
    "run_save( model, trial_identifier, fit_eras=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "trials = [\n",
    "    \"baseline\",\n",
    "    \"erasplit\",\n",
    "    \"erasplit_mixin\",\n",
    "    \"directional_erasplit\",\n",
    "    \"directional_erasplit_mixin\"\n",
    "]\n",
    "\n",
    "loaded_desc = []\n",
    "\n",
    "for trial in trials:\n",
    "\n",
    "    model = f\"{trial}_model.pkl\"\n",
    "    desc = f\"{trial}_desc.csv\"\n",
    "    validation = f\"{trial}_validation_data_with_preds.csv\"\n",
    "\n",
    "#     loaded_model = pickle.load(open(model, \"rb\"))\n",
    "#     loaded_desc = pd.read_csv(desc, index_col=0)\n",
    "#     loaded_validation = pd.read_csv(validation)\n",
    "\n",
    "    # Now you can use loaded_model, loaded_desc, and loaded_validation as needed\n",
    "    loaded_desc.append( pd.read_csv(desc, index_col=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>erasplit</th>\n",
       "      <th>erasplit_mixin</th>\n",
       "      <th>directional_erasplit</th>\n",
       "      <th>directional_erasplit_mixin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.012306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020185</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.019858</td>\n",
       "      <td>0.020063</td>\n",
       "      <td>0.020065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.049736</td>\n",
       "      <td>-0.043330</td>\n",
       "      <td>-0.044734</td>\n",
       "      <td>-0.042902</td>\n",
       "      <td>-0.048945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>-0.000583</td>\n",
       "      <td>-0.002111</td>\n",
       "      <td>-0.002547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.014734</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.012476</td>\n",
       "      <td>0.011249</td>\n",
       "      <td>0.011073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>0.026765</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.071494</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>0.066284</td>\n",
       "      <td>0.070439</td>\n",
       "      <td>0.069449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpe</th>\n",
       "      <td>0.710870</td>\n",
       "      <td>0.607492</td>\n",
       "      <td>0.665031</td>\n",
       "      <td>0.608760</td>\n",
       "      <td>0.613338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_rate</th>\n",
       "      <td>0.742063</td>\n",
       "      <td>0.716270</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.712302</td>\n",
       "      <td>0.702381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            baseline    erasplit  erasplit_mixin  directional_erasplit  \\\n",
       "count     499.000000  499.000000      499.000000            499.000000   \n",
       "mean        0.014349    0.011998        0.013206              0.012214   \n",
       "std         0.020185    0.019749        0.019858              0.020063   \n",
       "min        -0.049736   -0.043330       -0.044734             -0.042902   \n",
       "25%         0.000213   -0.001809       -0.000583             -0.002111   \n",
       "50%         0.014734    0.012376        0.012476              0.011249   \n",
       "75%         0.028303    0.026073        0.026765              0.025079   \n",
       "max         0.071494    0.066212        0.066284              0.070439   \n",
       "sharpe      0.710870    0.607492        0.665031              0.608760   \n",
       "win_rate    0.742063    0.716270        0.730159              0.712302   \n",
       "\n",
       "          directional_erasplit_mixin  \n",
       "count                     499.000000  \n",
       "mean                        0.012306  \n",
       "std                         0.020065  \n",
       "min                        -0.048945  \n",
       "25%                        -0.002547  \n",
       "50%                         0.011073  \n",
       "75%                         0.026942  \n",
       "max                         0.069449  \n",
       "sharpe                      0.613338  \n",
       "win_rate                    0.702381  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(loaded_desc, axis=1)\n",
    "results.columns = trials\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tree_dev]",
   "language": "python",
   "name": "conda-env-tree_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
